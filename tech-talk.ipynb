{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac0b771-84da-4992-aa10-b62d3e7e28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAMER ChatBot\n",
    "from flask import Flask, request\n",
    "import requests\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# integration with gaming platforms or APIs\n",
    "GAME_API_URL = \"https://api.example.com\"\n",
    "HARDWARE_API_URL = \"https://api.example.com\"\n",
    "\n",
    "# natural language processing (NLP) and sentiment analysis\n",
    "NLP_API_URL = \"https://api.example.com/nlp\"\n",
    "\n",
    "# machine learning algorithms\n",
    "LEARNING_API_URL = \"https://api.example.com/learning\"\n",
    "\n",
    "# integration with live chat or voice chat platforms\n",
    "LIVE_CHAT_API_URL = \"https://api.example.com/live_chat\"\n",
    "\n",
    "# define routes for handling incoming messages from the user\n",
    "@app.route('/', methods=['POST'])\n",
    "def handle_message():\n",
    "    message = request.form['message']\n",
    "    \n",
    "    # use NLP API to analyze the user's message and determine their intent\n",
    "    intent = get_intent(message)\n",
    "    \n",
    "    # diagnose and troubleshoot common technical issues\n",
    "    if intent == \"technical_issues\":\n",
    "        response = troubleshoot_technical_issues(message)\n",
    "        \n",
    "    # provide personalized recommendations based on user preferences and habits\n",
    "    elif intent == \"recommendations\":\n",
    "        response = get_recommendations(message)\n",
    "        \n",
    "    # provide general assistance and support\n",
    "    else:\n",
    "        response = \"Thank you for contacting our support team. How may I assist you?\"\n",
    "        \n",
    "    # use machine learning API to learn from user interactions and improve over time\n",
    "    update_learning_api(message, intent, response)\n",
    "    \n",
    "    # use live chat API to provide real-time assistance to the user\n",
    "    send_live_chat_response(response)\n",
    "    \n",
    "    return \"success\"\n",
    "\n",
    "# function to diagnose and troubleshoot common technical issues\n",
    "def troubleshoot_technical_issues(message):\n",
    "    if \"lag\" in message:\n",
    "        return \"To reduce lag, try closing any background applications that may be using up system resources.\"\n",
    "    elif \"crash\" in message:\n",
    "        return \"To troubleshoot game crashes, try updating your graphics card drivers or reinstalling the game.\"\n",
    "    elif \"connectivity\" in message:\n",
    "        return \"To troubleshoot connectivity issues, try resetting your router or contacting your internet service provider.\"\n",
    "    else:\n",
    "        return \"I'm sorry, I'm not sure how to help with that issue.\"\n",
    "\n",
    "# function to get personalized recommendations based on user preferences and habits\n",
    "def get_recommendations(message):\n",
    "    user_id = get_user_id(message)\n",
    "    user_preferences = get_user_preferences(user_id)\n",
    "    similar_users = get_similar_users(user_preferences)\n",
    "    recommended_games = get_recommended_games(similar_users)\n",
    "    \n",
    "    return \"Based on your gaming habits and preferences, we recommend the following games: \" + \", \".join(recommended_games)\n",
    "\n",
    "# function to get the user ID associated with the incoming message\n",
    "def get_user_id(message):\n",
    "    # code to retrieve the user ID from the message\n",
    "    pass\n",
    "\n",
    "# function to get the user's preferences\n",
    "def get_user_preferences(user_id):\n",
    "    preferences = requests.get(GAME_API_URL + \"/users/\" + user_id + \"/preferences\")\n",
    "    return preferences.json()\n",
    "\n",
    "# function to get similar users based on preferences\n",
    "def get_similar_users(user_preferences):\n",
    "    similar_users = requests.post(GAME_API_URL + \"/users/similar\", json=user_preferences)\n",
    "    return similar_users.json()\n",
    "\n",
    "# function to get recommended games based on similar users\n",
    "def get_recommended_games(similar_users):\n",
    "    recommended_games = requests.post(GAME_API_URL + \"/games/recommended\", json=similar_users)\n",
    "    return recommended_games.json()\n",
    "\n",
    "# function to use NLP API to analyze user's message and determine intent\n",
    "def get_intent(message):\n",
    "    response = requests.post(NLP_API_URL, data={\"message\": message})\n",
    "    intent = response.json()[\"intent\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0ae81-8a25-492e-a8ec-e4694cd9bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP code\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text=\"Hello dear students, Welcome to NLP workshop with python!\"\n",
    "def tokenize(sentence):\n",
    "    # Tokenize the sentence\n",
    "    doc = nlp(sentence)\n",
    "    # Return tokens\n",
    "    return [X.text for X in doc]\n",
    "print(tokenize(text))\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)\n",
    "clean_words = []\n",
    "for token in tokenize(text):\n",
    "    if token not in stopwords:\n",
    "        clean_words.append(token)\n",
    "\n",
    "clean_words\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "def return_stem(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return [stemmer.stem(X.text) for X in doc]\n",
    "print(return_stem(text))\n",
    "def return_NER(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # Return text and label for each entity\n",
    "    return [(X.text, X.label_) for X in doc.ents]\n",
    "test=\"Tunisia is a very nice country and we have Instadeep company\"\n",
    "return_NER(test)\n",
    "#Spacy offers \"Visualizers\", graphical tools that display the results of named entity recognition or labeling\n",
    "from spacy import displacy\n",
    "doc = nlp(test)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "colors = {\"GPE\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "options = {\"ents\": [\"GPE\"], \"colors\": colors}\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True, options=options)\n",
    "def return_POS(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # return POS of each token\n",
    "    return [(X, X.pos_) for X in doc]\n",
    "return_POS(text)\n",
    "import numpy as np\n",
    "\n",
    "def return_word_embedding(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # return the vector of each token\n",
    "    return [(X.vector) for X in doc]\n",
    "return_word_embedding(text)\n",
    "def return_mean_embedding(sentence):\n",
    "    doc = nlp(sentence)\n",
    "# return the average of the vectors for each sentence\n",
    "    return np.mean([(X.vector) for X in doc], axis=0)\n",
    "test_2 = \"the NLP workshop started at 2pm\"\n",
    "test_3 = \"I want to eat pizza\"\n",
    "test_4 = \"It's 18 degrees here\"\n",
    "np.linalg.norm(return_mean_embedding(text)-return_mean_embedding(test_2))\n",
    "np.linalg.norm(return_mean_embedding(text)-return_mean_embedding(test_3))\n",
    "np.linalg.norm(return_mean_embedding(text)-return_mean_embedding(test_4))\n",
    "!pip install transformers\n",
    "import torch\n",
    "from transformers import *\n",
    "# Tokeniser, Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-multilingual-cased')\n",
    "model.eval()\n",
    "#The model.eval() line allows you to switch the model to evaluation mode.\n",
    "# tokenized text\n",
    "text2=\"Comment ça va ? Bien merci, un peu stressé avant l'examen\"\n",
    "tokenized_text = tokenizer.tokenize(text2)\n",
    "print(tokenized_text)\n",
    "# Convert text to indexes\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(indexed_tokens)\n",
    "segments_ids = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "print(segments_ids)\n",
    "# Transform to tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "predictions = model(tokens_tensor, segments_tensors)\n",
    "if np.argmax(predictions) == 0:\n",
    "    print(\"Continuation of the sentence\")\n",
    "else:\n",
    "    print(\"Not a Continuation of the sentence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
